### 机器学习课程

#### 朴素贝叶斯

- 散点图(Scatter plot)
- 决策面(Descision surface)
- 朴素贝叶斯(Naive Bayes)
```
    先验
    归一化
    后验
```

#### SVM(Support Vector Machine)

```
寻找介于两个类别的数据之间的**超平面**分割线
```

#### 决策树(Decision Tree)

```
熵(entropy): 决定在何处分割数据的方式
信息增益(information gain): 熵(parent) - 分割父项后生成子项的熵的加权平均
决策树算法会最大程度提升信息增益
```

#### 回归(Regression)

```
线性方程 `y = 斜率(slope) * x + 截距(intercept)`
`error`是指误差而不是指错误
最小误差平方和算法(Minimizing the sum of squared Errors):
1. 最小二乘法 (ordiary least squares)
2. 梯度下降 (gradient descent)
```

#### 异常值(Outlier)

```
如何检测
删除算法

1.Train
2.Remove point with largest residual error (may 10%)
3.Re-Train

2 && 3 repeat

```

#### 聚类(Clustering)

```
Most use algorithm: K-meas

1.Assign
2.Optimize

局部最小值(Local minimum)

```


#### 特征缩放(Feature scaling)

```

```


















